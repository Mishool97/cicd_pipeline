name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  unit-tests:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run unit tests
      run: |
        pytest tests/unit

  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run integration tests
      run: |
        pytest tests/integration

  deploy-databricks:
    runs-on: ubuntu-latest
    needs: integration-tests

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Install Databricks CLI
      run: |
        pip install databricks-cli

    - name: Configure Databricks CLI
      env:
        DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
        DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      run: |
        databricks configure --token <<EOF
        $DATABRICKS_HOST
        $DATABRICKS_TOKEN
        EOF

    - name: Upload Notebooks
      run: |
        databricks workspace import_dir databricks/notebooks /Users/${{ secrets.DATABRICKS_USER }}/notebooks --overwrite

    - name: Create or Update Job
      run: |
        databricks jobs create --json-file databricks/jobs/example_job.json || databricks jobs reset --job-id $(databricks jobs list | grep 'example_job' | awk '{print $1}') --json-file databricks/jobs/example_job.json
